{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "from calendar import c\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "from collections import Counter\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,OneSidedSelection\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "import multiprocessing\n",
    "from model import Model, Model_BCE\n",
    "cpu_cont = multiprocessing.cpu_count()\n",
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                          BertConfig, BertForMaskedLM, BertTokenizer,\n",
    "                          GPT2Config, GPT2LMHeadModel, GPT2Tokenizer,\n",
    "                          OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
    "                          DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_tokens,\n",
    "                 input_ids,\n",
    "                 idx,\n",
    "                 label,\n",
    "\n",
    "                 ):\n",
    "        self.input_tokens = input_tokens\n",
    "        self.input_ids = input_ids\n",
    "        self.idx = str(idx)\n",
    "        self.label = label\n",
    "def convert_examples_to_features(js, tokenizer, args):\n",
    "    # source\n",
    "    code = ' '.join(js['func'].split())\n",
    "    code_tokens = tokenizer.tokenize(code)[:args.block_size - 2]\n",
    "    source_tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]\n",
    "    source_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = args.block_size - len(source_ids)\n",
    "    source_ids += [tokenizer.pad_token_id] * padding_length\n",
    "    return InputFeatures(source_tokens, source_ids, js['idx'], js['target']),code\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, args, file_path=None):\n",
    "        label_count = []\n",
    "        self.examples = []\n",
    "        self.codes = []\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                js = json.loads(line.strip())\n",
    "                example,code = convert_examples_to_features(js, tokenizer, args)\n",
    "                label_count.append(example.label)\n",
    "                self.examples.append(example)\n",
    "                self.codes.append(code)\n",
    "#         logger.info(\"label ratio: {}\".format(Counter(label_count)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.examples[i].input_ids), torch.tensor(self.examples[i].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'msr_outout/ros_2x/checkpoint-best/model.bin'\n",
    "test_data_file = '../msr_dataset/origin/data_split_0/test.jsonl'\n",
    "msr_line_file = '../msr_dataset/msr_line.jsonl'\n",
    "config_class, model_class, tokenizer_class = RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "tokenizer = tokenizer_class.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_class(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    block_size = 400\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_BCE(model,config, tokenizer, args=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_BCE(\n",
       "  (encoder): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(output_dir))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_js_with_index(index_i,test_data_file):\n",
    "    with open(test_data_file) as f:\n",
    "        line = f.readlines()[index_i]\n",
    "        js = json.loads(line.strip())\n",
    "        return js\n",
    "\n",
    "def get_line_with_index(index_i,msr_line_file):\n",
    "    with open(msr_line_file) as f:\n",
    "        line = f.readlines()[index_i]\n",
    "        js = json.loads(line.strip())\n",
    "        return js['lines_before']\n",
    "    \n",
    "def func_to_input(func):\n",
    "    code = ' '.join(func.split())\n",
    "    code_tokens = tokenizer.tokenize(code)[:args.block_size - 2]\n",
    "    source_tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]\n",
    "    source_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = args.block_size - len(source_ids)\n",
    "    source_ids += [tokenizer.pad_token_id] * padding_length\n",
    "    return source_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_js_with_index(10905,test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_data_file) as f:\n",
    "    total_test = len(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_pipeline:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    def pred(self,funcs):\n",
    "        ret_probs = []\n",
    "        dataloader = DataLoader(funcs, batch_size=32, shuffle=False)\n",
    "        for funcs in dataloader:\n",
    "            input_idxs = []\n",
    "            for index,func in enumerate(funcs):\n",
    "                input_idx = func_to_input(func)\n",
    "                input_idxs.append(input_idx)\n",
    "            model_input = torch.tensor(input_idxs,device=device)\n",
    "            model_output = self.model(model_input).cpu().detach().numpy()\n",
    "            ret_probs.append(model_output)\n",
    "            del model_input,model_output\n",
    "        clf_outputs = np.row_stack(ret_probs)\n",
    "        diff = 1-clf_outputs\n",
    "        ret_prob = np.concatenate((diff,clf_outputs),axis=1)\n",
    "        return np.array(ret_prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = model_pipeline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "class_names = ['non_vul', 'vul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                 | 29/37728 [00:01<24:44, 25.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 true positive 0.995524525642395, curr: 30/37728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                | 84/37728 [00:38<41:07, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 true positive 0.9994556307792664, curr: 84/37728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                             | 134/37728 [01:22<1:01:28, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 true positive 0.998969316482544, curr: 138/37728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                             | 134/37728 [01:40<1:01:28, 10.19it/s]"
     ]
    }
   ],
   "source": [
    "prob_list = []\n",
    "exp_tup_list = []\n",
    "line_list = []\n",
    "index_list = []\n",
    "for test_index in tqdm(range(0,total_test)):\n",
    "    js = get_js_with_index(test_index,test_data_file)\n",
    "    idx = js['idx']\n",
    "    if js['target'] == 1: # for all Vulnearble\n",
    "        line = get_line_with_index(idx,msr_line_file)\n",
    "        if line != None:\n",
    "            func = js['func']\n",
    "            prob = pipeline.pred([func])\n",
    "            if prob[0][1] > 0.5:\n",
    "                index_list.append(test_index)\n",
    "                try: \n",
    "                    print(f'{len(prob_list)} true positive {prob[0][1]}, curr: {test_index}/{total_test}')\n",
    "                    # true positive\n",
    "                    # # now see if he really see the importance vulnerable line!!!!\n",
    "                    explainer = LimeTextExplainer(class_names=class_names)\n",
    "                    exp = explainer.explain_instance(func, pipeline.pred, num_features=len(func.split()))\n",
    "                    # break\n",
    "                    exp = exp.as_list()\n",
    "                    exp_tup_list.append(exp)\n",
    "                    line_list.append(line)\n",
    "                    prob_list.append(prob[0][1])\n",
    "                    index_list.append(test_index)\n",
    "                except:\n",
    "                    print(f'error in {func} - {test_index}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'exp_output/2x_TP_list.txt', 'w') as f:\n",
    "#     f.write(str(index_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'exp_output/ros_TP_list.txt', 'r') as f:\n",
    "#     x = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(index_list) & set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_result = zip(exp_tup_list,line_list,prob_list,index_list)\n",
    "sorted_zip = sorted(zipped_result, key=lambda x: x[2],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sorted_zip, open( f'lime_output/msr_2x_zip_exp_line_prob.pkl', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_list = []\n",
    "# for index in index_list:\n",
    "#     js = get_js_with_index(index,test_data_file)\n",
    "#     if len(js['func'].splitlines()) <= 30:\n",
    "#         temp_list.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_list = [4993, 5210, 5258, 5274, 5355, 5417, 5510, 5677, 5708, 5798, 5935, 6040, 6351, 6370, 6380, 6493, 6775, 6810, 6836, 7049, 7417, 7533, 7592, 7601, 7620, 7718, 8373, 8434, 8449, 8477, 8560, 8655, 8693, 8694, 8792, 8813, 9046, 9295, 9879, 10049, 10057, 10150, 10245, 10252, 10310, 10357, 10399, 10507, 10519, 10553, 10634, 10740, 10905, 10959, 11042, 11054, 11274, 11467, 11475, 11749, 12003, 12220, 12372, 12437, 12642, 12660, 12680, 12899, 12915, 13103, 13104, 13197, 13279, 13712, 13743, 13753, 13766, 13783, 13976, 14331, 14367, 14769, 14858, 15212, 15267, 15351, 15615, 15961, 15979, 15991, 16030, 16147, 16183, 16208, 16261, 16274, 16328, 16384, 16507, 16647, 16714, 16797, 16828, 16892, 16922, 17011, 17059, 17089, 17095, 17126, 17472, 17607, 17675, 17710, 17776, 18033, 18067, 18112, 18403, 18612, 18814, 18816, 18911, 19038, 19241, 19252, 19460, 19468, 19498, 19575, 19605, 19656, 19667, 20357, 20393, 20430, 20466, 20661, 20878, 20965, 20974, 21004, 21087, 21183, 21289, 21517, 21574, 21833, 22065, 22083, 22151, 22331, 22373, 22563, 22601, 22778, 23036, 23398, 23482, 23838, 23898, 24184, 24834, 24901, 24904, 24920, 25005, 25171, 25192, 25254, 25351, 25445, 25447, 25450, 25453, 25507, 25910, 25979, 26102, 26427, 26578, 26743, 27176, 27378, 27636, 27773, 27815, 27880, 28100, 28119, 28140, 28299, 28737, 29013, 29154, 29181, 29314, 29741, 29927, 30021, 30030, 30127, 30270, 30537, 30830, 31000, 31160, 31168, 31341, 31511, 31558, 31562, 31572, 31617, 31799, 32000, 32260, 32308, 32361, 32639, 32692, 33200, 33325, 33348, 33410, 33510, 34104, 34113, 34144, 34210, 34236, 34238, 34651, 34700, 34992, 35028, 35079, 35087, 35143, 35358, 35506, 35580, 35800, 36061, 36249, 36460, 36548, 36650, 36670, 36727, 36802, 36903, 36943, 37072, 37368, 37458]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in tqdm(temp_list):\n",
    "#     js = get_js_with_index(index,test_data_file)\n",
    "#     func = js['func']\n",
    "#     line = get_line_with_index(js['idx'],msr_line_file)\n",
    "#     explainer = LimeTextExplainer(class_names=class_names)\n",
    "#     exp = explainer.explain_instance(func, pipeline.pred, num_features=len(func.split()))\n",
    "\n",
    "#     exp.local_exp[1] = [tup for tup in exp.local_exp[1] if tup[1] > 0][:5]\n",
    "#     hit = False\n",
    "#     for exp_token,prob in exp.as_list():\n",
    "#         if exp_token in line:\n",
    "#             hit = True\n",
    "#     if not hit:\n",
    "#         break\n",
    "#     # exp.save_to_file(f'exp_output/{index}_exp.html')\n",
    "#     # with open(f'exp_output/{index}_line.txt', 'w') as f:\n",
    "#     #     f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.save_to_file(f'exp_output/failhit_{index}_exp.html')\n",
    "# with open(f'exp_output/failhit_{index}_line.txt', 'w') as f:\n",
    "#     f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_env",
   "language": "python",
   "name": "transformer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
