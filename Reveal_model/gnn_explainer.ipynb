{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from cmath import log\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "from data_loader.dataset import DataSet\n",
    "from modules.model import DevignModel, GGNNSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to proceed dataset dir as the input dataset for interpretation\n",
    "input_dir = 'reveal_model_data/msr_data/ros_4x/'\n",
    "processed_data_path = os.path.join(input_dir, 'processed.bin')\n",
    "dataset = pickle.load(open(processed_data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27726"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.initialize_test_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GGNNSum(input_dim=dataset.feature_size, output_dim=200,num_steps=6, max_edge_types=dataset.max_edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from data_loader.batch_graph import GGNNBatchGraph\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained-model to interpretation\n",
    "model.load_state_dict(torch.load('msr_result/ggnn_model/msr_4x/0/Model_ep_49.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GGNNSum(\n",
       "  (ggnn): GatedGraphConv(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (1): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (3): Linear(in_features=200, out_features=200, bias=True)\n",
       "    )\n",
       "    (gru): GRUCell(200, 200)\n",
       "  )\n",
       "  (classifier): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when explain model with Sampling_R\n",
    "class GGNNSum_single(nn.Module):\n",
    "    def __init__(self, GGNNSum):\n",
    "        super(GGNNSum_single, self).__init__()\n",
    "        self.net = GGNNSum\n",
    "\n",
    "    def forward(self, graph, feat, eweight=None):\n",
    "        batch_graph = GGNNBatchGraph()\n",
    "        batch_graph.add_subgraph(copy.deepcopy(graph))\n",
    "        outputs = self.net(batch_graph,device='cuda:0')\n",
    "        return torch.tensor([[1-outputs, outputs]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when explain model with Sampling_L\n",
    "class GGNNSum_latent(nn.Module):\n",
    "    def __init__(self, GGNNSum,skMLP):\n",
    "        super(GGNNSum_latent, self).__init__()\n",
    "        self.net = GGNNSum\n",
    "        self.clf = skMLP\n",
    "        \n",
    "    def forward(self,graph,feat,eweight=None):\n",
    "        device = 'cuda:0'\n",
    "        batch_graph = GGNNBatchGraph()\n",
    "        batch_graph.add_subgraph(copy.deepcopy(graph))\n",
    "        graph, features, edge_types = batch_graph.get_network_inputs(cuda=True,device=device)\n",
    "        graph = graph.to(device)\n",
    "        features = features.to(device)\n",
    "        edge_types = edge_types.to(device)\n",
    "        outputs = self.net.ggnn(graph, features, edge_types)\n",
    "        h_i, _ = batch_graph.de_batchify_graphs(outputs)\n",
    "        digit = h_i.sum(dim=1).cpu().detach().numpy()\n",
    "        clf_output = self.clf.predict_proba(digit)\n",
    "        del graph,edge_types,features\n",
    "        return torch.tensor(clf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when explain model with Sampling_L, load in the classifier you trained with sampling_L\n",
    "# clf = pickle.load(open('msr_result/backbone_ggnn/smote/sk_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch between sampling_L and R\n",
    "exp_model = GGNNSum_single(model)\n",
    "# exp_model = GGNNSum_latent(model,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch.explain import GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnnexplainer = GNNExplainer(exp_model,num_hops=1,log =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36988f4744da4b50973a708ccb11d7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27726 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TP_explaination_dict = {}\n",
    "total_test_item = dataset.initialize_test_batch()\n",
    "for index in tqdm(range(total_test_item)):\n",
    "    target = dataset.test_examples[index].target\n",
    "    if target == 1:\n",
    "        graph = dataset.test_examples[index].graph\n",
    "        if graph.num_edges() > 10 and graph.num_nodes() > 10:\n",
    "            features = graph.ndata['features']\n",
    "            pred = exp_model(graph,features)\n",
    "#             print(pred)\n",
    "#             break\n",
    "            if pred[0][1] > 0.5:\n",
    "#                 print(index,'tp')\n",
    "                _ ,edge_mask = gnnexplainer.explain_graph(graph=graph,feat=features)\n",
    "                top_10 = np.argpartition(edge_mask.numpy(), -10)[-10:]\n",
    "                node_list = []\n",
    "                for x in top_10:\n",
    "                    node_1,node_2 = graph.find_edges(x)\n",
    "                    node_list.append(node_1.numpy()[0])\n",
    "                    node_list.append(node_2.numpy()[0])\n",
    "                TP_explaination_dict[index] = node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TP_explaination_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27726"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_test_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TP_explaination_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the explaination results for further analysis\n",
    "import pickle\n",
    "with open('gnnexplainer_result/msr_4x_split_0_hop_1.pkl', 'wb') as fp:\n",
    "    pickle.dump(TP_explaination_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_env",
   "language": "python",
   "name": "transformer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}